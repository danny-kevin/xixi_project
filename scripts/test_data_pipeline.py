"""
æµ‹è¯•æ•°æ®é¢„å¤„ç†ç®¡é“
Test Data Preprocessing Pipeline

éªŒè¯æ•°æ®åŠ è½½ã€é¢„å¤„ç†å’Œæ•°æ®é›†åˆ›å»ºåŠŸèƒ½
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.data import prepare_data, DataPipeline


def test_data_pipeline():
    """æµ‹è¯•å®Œæ•´çš„æ•°æ®é¢„å¤„ç†ç®¡é“"""
    
    print("\n" + "=" * 70)
    print("ğŸ§ª æµ‹è¯•æ•°æ®é¢„å¤„ç†ç®¡é“")
    print("=" * 70 + "\n")
    
    # æ•°æ®ç›®å½•
    data_dir = project_root / 'data'
    
    # æ£€æŸ¥æ•°æ®æ˜¯å¦å­˜åœ¨
    raw_dir = data_dir / 'raw'
    if not raw_dir.exists() or not any(raw_dir.glob('*.csv')):
        print("âš ï¸  æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œæ­£åœ¨ç”Ÿæˆç¤ºä¾‹æ•°æ®...")
        from scripts.generate_sample_data import generate_all_sample_data
        generate_all_sample_data(output_dir=str(raw_dir))
        print()
    
    try:
        # æ–¹å¼1: ä½¿ç”¨ä¾¿æ·å‡½æ•°
        print("ğŸ“Œ æ–¹å¼1: ä½¿ç”¨ prepare_data() ä¾¿æ·å‡½æ•°\n")
        train_loader, val_loader, test_loader, preprocessor = prepare_data(
            data_dir=str(data_dir),
            window_size=21,
            horizon=7,
            batch_size=32,
            num_workers=0  # Windowsä¸Šè®¾ç½®ä¸º0
        )
        
        print("\n" + "=" * 70)
        print("âœ… æ•°æ®å‡†å¤‡æˆåŠŸï¼")
        print("=" * 70)
        
        # éªŒè¯æ•°æ®
        print("\nğŸ“Š æ•°æ®éªŒè¯:")
        print("-" * 70)
        
        # è·å–ä¸€ä¸ªæ‰¹æ¬¡
        for batch_x, batch_y in train_loader:
            print(f"âœ“ è®­ç»ƒæ‰¹æ¬¡å½¢çŠ¶:")
            print(f"  - è¾“å…¥ (X): {batch_x.shape}")
            print(f"  - ç›®æ ‡ (y): {batch_y.shape}")
            print(f"  - æ•°æ®ç±»å‹: {batch_x.dtype}")
            break
        
        for batch_x, batch_y in val_loader:
            print(f"\nâœ“ éªŒè¯æ‰¹æ¬¡å½¢çŠ¶:")
            print(f"  - è¾“å…¥ (X): {batch_x.shape}")
            print(f"  - ç›®æ ‡ (y): {batch_y.shape}")
            break
        
        for batch_x, batch_y in test_loader:
            print(f"\nâœ“ æµ‹è¯•æ‰¹æ¬¡å½¢çŠ¶:")
            print(f"  - è¾“å…¥ (X): {batch_x.shape}")
            print(f"  - ç›®æ ‡ (y): {batch_y.shape}")
            break
        
        # æµ‹è¯•åå½’ä¸€åŒ–
        print("\n" + "-" * 70)
        print("ğŸ”„ æµ‹è¯•åå½’ä¸€åŒ–åŠŸèƒ½:")
        print("-" * 70)
        
        import numpy as np
        test_data = np.array([[0.5], [0.6], [0.7]])
        
        # è·å–ç¬¬ä¸€ä¸ªç‰¹å¾çš„scaler
        feature_names = list(preprocessor.scalers.keys())
        if feature_names:
            first_feature = feature_names[0]
            original = preprocessor.inverse_transform(test_data, first_feature)
            print(f"âœ“ å½’ä¸€åŒ–æ•°æ®: {test_data.flatten()}")
            print(f"âœ“ åå½’ä¸€åŒ–å: {original}")
        
        print("\n" + "=" * 70)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("=" * 70 + "\n")
        
        return True
        
    except Exception as e:
        print("\n" + "=" * 70)
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        print("=" * 70 + "\n")
        import traceback
        traceback.print_exc()
        return False


def test_individual_components():
    """æµ‹è¯•å„ä¸ªç»„ä»¶"""
    
    print("\n" + "=" * 70)
    print("ğŸ§ª æµ‹è¯•å„ä¸ªç»„ä»¶")
    print("=" * 70 + "\n")
    
    data_dir = project_root / 'data'
    
    try:
        # æµ‹è¯•DataLoader
        print("1ï¸âƒ£ æµ‹è¯• DataLoader")
        print("-" * 70)
        from src.data import DataLoader
        
        loader = DataLoader(str(data_dir))
        data_dict = loader.load_all_data()
        
        print(f"âœ“ åŠ è½½äº† {len(data_dict)} ä¸ªæ•°æ®æº:")
        for name, df in data_dict.items():
            print(f"  - {name}: {df.shape}")
        
        merged = loader.merge_data_sources(data_dict)
        print(f"âœ“ åˆå¹¶åæ•°æ®å½¢çŠ¶: {merged.shape}")
        
        # æµ‹è¯•DataPreprocessor
        print("\n2ï¸âƒ£ æµ‹è¯• DataPreprocessor")
        print("-" * 70)
        from src.data import DataPreprocessor
        
        preprocessor = DataPreprocessor()
        
        # æµ‹è¯•ç¼ºå¤±å€¼å¤„ç†
        processed = preprocessor.handle_missing_values(merged)
        print(f"âœ“ ç¼ºå¤±å€¼å¤„ç†å®Œæˆï¼Œå‰©ä½™ç¼ºå¤±å€¼: {processed.isnull().sum().sum()}")
        
        # æµ‹è¯•å¼‚å¸¸å€¼æ£€æµ‹
        outliers = preprocessor.detect_outliers(processed)
        print(f"âœ“ æ£€æµ‹åˆ° {outliers.sum().sum()} ä¸ªå¼‚å¸¸å€¼")
        
        # æµ‹è¯•å½’ä¸€åŒ–
        normalized = preprocessor.normalize(processed)
        print(f"âœ“ å½’ä¸€åŒ–å®Œæˆï¼Œæ•°æ®èŒƒå›´: [{normalized.min().min():.3f}, {normalized.max().max():.3f}]")
        
        # æµ‹è¯•æ—¶é—´çª—å£åˆ›å»º
        import numpy as np
        data_array = normalized.values
        X, y = preprocessor.create_time_windows(data_array, window_size=21, horizon=7)
        print(f"âœ“ æ—¶é—´çª—å£åˆ›å»ºå®Œæˆ: X={X.shape}, y={y.shape}")
        
        # æµ‹è¯•æ•°æ®åˆ’åˆ†
        train, val, test = preprocessor.temporal_train_test_split(X)
        print(f"âœ“ æ•°æ®åˆ’åˆ†å®Œæˆ: train={len(train)}, val={len(val)}, test={len(test)}")
        
        # æµ‹è¯•Dataset
        print("\n3ï¸âƒ£ æµ‹è¯• EpidemicDataset")
        print("-" * 70)
        from src.data import EpidemicDataset
        
        dataset = EpidemicDataset(X[:100], y[:100])
        print(f"âœ“ æ•°æ®é›†å¤§å°: {len(dataset)}")
        print(f"âœ“ ç‰¹å¾ç»´åº¦: {dataset.get_feature_dim()}")
        print(f"âœ“ çª—å£å¤§å°: {dataset.get_window_size()}")
        
        sample_x, sample_y = dataset[0]
        print(f"âœ“ æ ·æœ¬å½¢çŠ¶: X={sample_x.shape}, y={sample_y.shape}")
        
        print("\n" + "=" * 70)
        print("âœ… æ‰€æœ‰ç»„ä»¶æµ‹è¯•é€šè¿‡ï¼")
        print("=" * 70 + "\n")
        
        return True
        
    except Exception as e:
        print("\n" + "=" * 70)
        print(f"âŒ ç»„ä»¶æµ‹è¯•å¤±è´¥: {str(e)}")
        print("=" * 70 + "\n")
        import traceback
        traceback.print_exc()
        return False


if __name__ == '__main__':
    # è¿è¡Œæµ‹è¯•
    success1 = test_individual_components()
    success2 = test_data_pipeline()
    
    if success1 and success2:
        print("\nğŸŠ æ­å–œï¼æ•°æ®é¢„å¤„ç†æ¨¡å—å·²å®Œå…¨å®ç°å¹¶é€šè¿‡æµ‹è¯•ï¼\n")
        sys.exit(0)
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯\n")
        sys.exit(1)
