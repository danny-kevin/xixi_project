{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# æ³¨æ„åŠ›å¢å¼ºM-TCN-LSTM - å¿«é€Ÿå…¥é—¨\n",
                "\n",
                "æœ¬notebookæ¼”ç¤ºå¦‚ä½•ä½¿ç”¨è¯¥é¡¹ç›®è¿›è¡Œä¼ æŸ“ç—…é¢„æµ‹ã€‚\n",
                "\n",
                "## ğŸ“‹ ç›®å½•\n",
                "1. ç¯å¢ƒè®¾ç½®\n",
                "2. æ•°æ®å‡†å¤‡\n",
                "3. æ¨¡å‹è®­ç»ƒ\n",
                "4. æ¨¡å‹è¯„ä¼°\n",
                "5. å¯è§£é‡Šæ€§åˆ†æ"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ç¯å¢ƒè®¾ç½®"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "\n",
                "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„\n",
                "project_root = os.path.abspath('..')\n",
                "if project_root not in sys.path:\n",
                "    sys.path.insert(0, project_root)\n",
                "\n",
                "import torch\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from src.utils.config import load_config\n",
                "from src.utils.logger import setup_logger\n",
                "from src.utils.device_manager import DeviceManager\n",
                "\n",
                "# è®¾ç½®æ—¥å¿—\n",
                "logger = setup_logger('notebook', log_file='logs/notebook.log')\n",
                "logger.info('Notebook started')\n",
                "\n",
                "# è®¾ç½®è®¾å¤‡\n",
                "device_manager = DeviceManager()\n",
                "device = device_manager.get_device()\n",
                "logger.info(f'Using device: {device}')\n",
                "\n",
                "print(f\"âœ… PyTorch version: {torch.__version__}\")\n",
                "print(f\"âœ… Device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. æ•°æ®å‡†å¤‡\n",
                "\n",
                "### 2.1 åŠ è½½é…ç½®"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# åŠ è½½é»˜è®¤é…ç½®\n",
                "config = load_config('../configs/default_config.yaml')\n",
                "print(f\"Window size: {config.data.window_size}\")\n",
                "print(f\"Prediction horizon: {config.data.prediction_horizon}\")\n",
                "print(f\"Number of variables: {config.model.num_variables}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 åŠ è½½å’Œé¢„å¤„ç†æ•°æ®\n",
                "\n",
                "**æ³¨æ„**: è¿™éƒ¨åˆ†éœ€è¦ `01_data_preparation_agent` å®Œæˆå®ç°åæ‰èƒ½è¿è¡Œ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: åœ¨ 01_data_preparation_agent å®Œæˆåå–æ¶ˆæ³¨é‡Š\n",
                "\n",
                "# from src.data import DataLoader, DataPreprocessor, EpidemicDataset\n",
                "\n",
                "# # åŠ è½½æ•°æ®\n",
                "# data_loader = DataLoader(config.data.data_dir)\n",
                "# raw_data = data_loader.load_all_data()\n",
                "\n",
                "# # é¢„å¤„ç†\n",
                "# preprocessor = DataPreprocessor(config.data)\n",
                "# processed_data = preprocessor.preprocess(raw_data)\n",
                "\n",
                "# # åˆ›å»ºæ•°æ®é›†\n",
                "# train_dataset = EpidemicDataset(X_train, y_train)\n",
                "# val_dataset = EpidemicDataset(X_val, y_val)\n",
                "# test_dataset = EpidemicDataset(X_test, y_test)\n",
                "\n",
                "print(\"âš ï¸ æ•°æ®åŠ è½½åŠŸèƒ½å¾… 01_data_preparation_agent å®ç°\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.3 ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º\n",
                "\n",
                "åœ¨çœŸå®æ•°æ®å‡†å¤‡å¥½ä¹‹å‰ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¼”ç¤ºæµç¨‹"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®\n",
                "batch_size = 32\n",
                "seq_len = config.data.window_size\n",
                "num_variables = config.model.num_variables\n",
                "horizon = config.data.prediction_horizon\n",
                "\n",
                "# æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®\n",
                "X_dummy = torch.randn(100, seq_len, num_variables)\n",
                "y_dummy = torch.randn(100, horizon)\n",
                "\n",
                "print(f\"âœ… æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå®Œæˆ\")\n",
                "print(f\"   è¾“å…¥å½¢çŠ¶: {X_dummy.shape}\")\n",
                "print(f\"   è¾“å‡ºå½¢çŠ¶: {y_dummy.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. æ¨¡å‹è®­ç»ƒ\n",
                "\n",
                "### 3.1 åˆ›å»ºæ¨¡å‹\n",
                "\n",
                "**æ³¨æ„**: éœ€è¦å„æ¨¡å—Agentå®Œæˆå®ç°åæ‰èƒ½çœŸæ­£è¿è¡Œ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: åœ¨æ‰€æœ‰æ¨¡å‹Agentå®Œæˆåå–æ¶ˆæ³¨é‡Š\n",
                "\n",
                "# from src.models import AttentionMTCNLSTM, ModelFactory\n",
                "\n",
                "# # æ–¹å¼1: ç›´æ¥åˆ›å»º\n",
                "# model = AttentionMTCNLSTM(\n",
                "#     num_variables=config.model.num_variables,\n",
                "#     input_size=config.model.input_size,\n",
                "#     tcn_channels=config.model.tcn_channels,\n",
                "#     tcn_kernel_size=config.model.tcn_kernel_size,\n",
                "#     attention_embed_dim=config.model.attention_embed_dim,\n",
                "#     attention_num_heads=config.model.attention_num_heads,\n",
                "#     lstm_hidden_size=config.model.lstm_hidden_size,\n",
                "#     lstm_num_layers=config.model.lstm_num_layers,\n",
                "#     output_size=config.model.output_size,\n",
                "#     prediction_horizon=config.model.prediction_horizon,\n",
                "#     dropout=config.model.dropout,\n",
                "#     attention_dropout=config.model.attention_dropout\n",
                "# )\n",
                "\n",
                "# # æ–¹å¼2: ä½¿ç”¨å·¥å‚æ¨¡å¼\n",
                "# # model = ModelFactory.create_base_model(\n",
                "# #     num_variables=config.model.num_variables,\n",
                "# #     prediction_horizon=config.model.prediction_horizon\n",
                "# # )\n",
                "\n",
                "# model = model.to(device)\n",
                "# print(f\"âœ… æ¨¡å‹åˆ›å»ºå®Œæˆ\")\n",
                "# print(f\"   å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}\")\n",
                "\n",
                "print(\"âš ï¸ æ¨¡å‹åˆ›å»ºåŠŸèƒ½å¾…å„æ¨¡å—Agentå®ç°\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 è®­ç»ƒæ¨¡å‹"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: åœ¨ 05_model_integration_agent å®Œæˆåå–æ¶ˆæ³¨é‡Š\n",
                "\n",
                "# from src.training import Trainer, TrainingConfig\n",
                "\n",
                "# # åˆ›å»ºè®­ç»ƒå™¨\n",
                "# training_config = TrainingConfig(\n",
                "#     epochs=config.training.epochs,\n",
                "#     batch_size=config.training.batch_size,\n",
                "#     learning_rate=config.training.learning_rate,\n",
                "#     device=str(device)\n",
                "# )\n",
                "\n",
                "# trainer = Trainer(model, training_config)\n",
                "\n",
                "# # å¼€å§‹è®­ç»ƒ\n",
                "# history = trainer.train(train_loader, val_loader)\n",
                "\n",
                "# # ç»˜åˆ¶è®­ç»ƒæ›²çº¿\n",
                "# plt.figure(figsize=(12, 4))\n",
                "# plt.subplot(1, 2, 1)\n",
                "# plt.plot(history['train_loss'], label='Train Loss')\n",
                "# plt.plot(history['val_loss'], label='Val Loss')\n",
                "# plt.xlabel('Epoch')\n",
                "# plt.ylabel('Loss')\n",
                "# plt.legend()\n",
                "# plt.title('Training History')\n",
                "\n",
                "# plt.subplot(1, 2, 2)\n",
                "# plt.plot(history['learning_rate'])\n",
                "# plt.xlabel('Epoch')\n",
                "# plt.ylabel('Learning Rate')\n",
                "# plt.title('Learning Rate Schedule')\n",
                "# plt.tight_layout()\n",
                "# plt.show()\n",
                "\n",
                "print(\"âš ï¸ è®­ç»ƒåŠŸèƒ½å¾… 05_model_integration_agent å®ç°\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. æ¨¡å‹è¯„ä¼°\n",
                "\n",
                "### 4.1 è®¡ç®—è¯„ä¼°æŒ‡æ ‡"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: åœ¨ 06_evaluation_interpretation_agent å®Œæˆåå–æ¶ˆæ³¨é‡Š\n",
                "\n",
                "# from src.evaluation import ModelEvaluator, RegressionMetrics\n",
                "\n",
                "# # åˆ›å»ºè¯„ä¼°å™¨\n",
                "# evaluator = ModelEvaluator(model, device=str(device))\n",
                "\n",
                "# # è¯„ä¼°æ¨¡å‹\n",
                "# results = evaluator.evaluate(test_loader, return_predictions=True)\n",
                "\n",
                "# # æ‰“å°ç»“æœ\n",
                "# print(\"\\nğŸ“Š è¯„ä¼°ç»“æœ:\")\n",
                "# print(f\"  MSE:  {results['mse']:.4f}\")\n",
                "# print(f\"  RMSE: {results['rmse']:.4f}\")\n",
                "# print(f\"  MAE:  {results['mae']:.4f}\")\n",
                "# print(f\"  MAPE: {results['mape']:.2f}%\")\n",
                "# print(f\"  RÂ²:   {results['r2']:.4f}\")\n",
                "\n",
                "# # ç”ŸæˆæŠ¥å‘Š\n",
                "# report = evaluator.generate_report(results, save_path='results/evaluation_report.txt')\n",
                "# print(report)\n",
                "\n",
                "print(\"âš ï¸ è¯„ä¼°åŠŸèƒ½å¾… 06_evaluation_interpretation_agent å®ç°\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.2 å¯è§†åŒ–é¢„æµ‹ç»“æœ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: åœ¨å¯è§†åŒ–å·¥å…·å®Œæˆåå–æ¶ˆæ³¨é‡Š\n",
                "\n",
                "# from src.utils.visualization import Visualizer\n",
                "\n",
                "# visualizer = Visualizer(save_dir='results/figures')\n",
                "\n",
                "# # ç»˜åˆ¶é¢„æµ‹å¯¹æ¯”å›¾\n",
                "# fig = visualizer.plot_predictions(\n",
                "#     actual=results['targets'],\n",
                "#     predicted=results['predictions'],\n",
                "#     title='Epidemic Prediction Results',\n",
                "#     save_name='predictions'\n",
                "# )\n",
                "# plt.show()\n",
                "\n",
                "# # ç»˜åˆ¶æ®‹å·®åˆ†æ\n",
                "# fig = visualizer.plot_residuals(\n",
                "#     actual=results['targets'],\n",
                "#     predicted=results['predictions'],\n",
                "#     save_name='residuals'\n",
                "# )\n",
                "# plt.show()\n",
                "\n",
                "print(\"âš ï¸ å¯è§†åŒ–åŠŸèƒ½å¾…å®ç°\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. å¯è§£é‡Šæ€§åˆ†æ\n",
                "\n",
                "### 5.1 æ³¨æ„åŠ›æƒé‡å¯è§†åŒ–"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: åœ¨ 06_evaluation_interpretation_agent å®Œæˆåå–æ¶ˆæ³¨é‡Š\n",
                "\n",
                "# from src.evaluation import AttentionVisualizer\n",
                "\n",
                "# # åˆ›å»ºæ³¨æ„åŠ›å¯è§†åŒ–å™¨\n",
                "# att_visualizer = AttentionVisualizer(model, device=str(device))\n",
                "\n",
                "# # æå–æ³¨æ„åŠ›æƒé‡\n",
                "# sample_input = X_test[0:1].to(device)\n",
                "# attention_weights = att_visualizer.extract_attention_weights(sample_input)\n",
                "\n",
                "# # ç»˜åˆ¶æ—¶é—´æ³¨æ„åŠ›çƒ­åŠ›å›¾\n",
                "# fig = att_visualizer.plot_temporal_attention(\n",
                "#     attention_weights['self_attention'],\n",
                "#     save_path='results/figures/temporal_attention.png'\n",
                "# )\n",
                "# plt.show()\n",
                "\n",
                "# # ç»˜åˆ¶å˜é‡æ³¨æ„åŠ›\n",
                "# fig = att_visualizer.plot_variable_attention(\n",
                "#     attention_weights['variable_attention'],\n",
                "#     variable_names=config.data.feature_columns,\n",
                "#     save_path='results/figures/variable_attention.png'\n",
                "# )\n",
                "# plt.show()\n",
                "\n",
                "print(\"âš ï¸ å¯è§£é‡Šæ€§åˆ†æå¾… 06_evaluation_interpretation_agent å®ç°\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.2 ç‰¹å¾é‡è¦æ€§åˆ†æ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: åœ¨ 06_evaluation_interpretation_agent å®Œæˆåå–æ¶ˆæ³¨é‡Š\n",
                "\n",
                "# from src.evaluation import FeatureImportanceAnalyzer\n",
                "\n",
                "# # åˆ›å»ºç‰¹å¾é‡è¦æ€§åˆ†æå™¨\n",
                "# importance_analyzer = FeatureImportanceAnalyzer(model, device=str(device))\n",
                "\n",
                "# # è®¡ç®—æ’åˆ—é‡è¦æ€§\n",
                "# importance_scores = importance_analyzer.permutation_importance(\n",
                "#     X_test.to(device),\n",
                "#     y_test.to(device),\n",
                "#     feature_names=config.data.feature_columns,\n",
                "#     num_repeats=10\n",
                "# )\n",
                "\n",
                "# # ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§\n",
                "# fig = importance_analyzer.plot_feature_importance(\n",
                "#     importance_scores,\n",
                "#     title='Feature Importance Analysis',\n",
                "#     save_path='results/figures/feature_importance.png'\n",
                "# )\n",
                "# plt.show()\n",
                "\n",
                "# # æ‰“å°é‡è¦æ€§æ’å\n",
                "# print(\"\\nğŸ“Š ç‰¹å¾é‡è¦æ€§æ’å:\")\n",
                "# sorted_features = sorted(importance_scores.items(), key=lambda x: x[1], reverse=True)\n",
                "# for i, (feature, score) in enumerate(sorted_features, 1):\n",
                "#     print(f\"  {i}. {feature}: {score:.4f}\")\n",
                "\n",
                "print(\"âš ï¸ ç‰¹å¾é‡è¦æ€§åˆ†æå¾… 06_evaluation_interpretation_agent å®ç°\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. ä¿å­˜æ¨¡å‹å’Œç»“æœ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: åœ¨è®­ç»ƒå™¨å®Œæˆåå–æ¶ˆæ³¨é‡Š\n",
                "\n",
                "# # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
                "# trainer.save_checkpoint('checkpoints/best_model.pth', is_best=True)\n",
                "\n",
                "# # ä¿å­˜é…ç½®\n",
                "# from src.utils.config import save_config\n",
                "# save_config(config, 'results/config.yaml')\n",
                "\n",
                "# print(\"âœ… æ¨¡å‹å’Œé…ç½®å·²ä¿å­˜\")\n",
                "\n",
                "print(\"âš ï¸ æ¨¡å‹ä¿å­˜åŠŸèƒ½å¾…å®ç°\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ğŸ“ æ€»ç»“\n",
                "\n",
                "æœ¬notebookæ¼”ç¤ºäº†å®Œæ•´çš„æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°æµç¨‹ï¼š\n",
                "\n",
                "1. âœ… ç¯å¢ƒè®¾ç½®å’Œé…ç½®åŠ è½½\n",
                "2. â³ æ•°æ®åŠ è½½å’Œé¢„å¤„ç† (å¾… 01_data_preparation_agent å®ç°)\n",
                "3. â³ æ¨¡å‹åˆ›å»ºå’Œè®­ç»ƒ (å¾…å„æ¨¡å—Agentå®ç°)\n",
                "4. â³ æ¨¡å‹è¯„ä¼°å’Œå¯è§†åŒ– (å¾… 06_evaluation_interpretation_agent å®ç°)\n",
                "5. â³ å¯è§£é‡Šæ€§åˆ†æ (å¾… 06_evaluation_interpretation_agent å®ç°)\n",
                "\n",
                "### ä¸‹ä¸€æ­¥\n",
                "\n",
                "è¯·æŒ‰ç…§ä»¥ä¸‹é¡ºåºè®©å„Agentå®Œæˆå®ç°ï¼š\n",
                "1. 01_data_preparation_agent\n",
                "2. 02_mtcn_module_agent\n",
                "3. 03_attention_mechanism_agent\n",
                "4. 04_lstm_module_agent\n",
                "5. 05_model_integration_agent\n",
                "6. 06_evaluation_interpretation_agent\n",
                "\n",
                "å®Œæˆåï¼Œå–æ¶ˆæœ¬notebookä¸­çš„æ³¨é‡Šå³å¯è¿è¡Œå®Œæ•´æµç¨‹ã€‚"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}