一、研究目标、研究内容和拟解决的关键问题
1.研究目标
本研究的总目标是构建一种注意力增强的M-TCN-LSTM混合神经网络模型，提升对复杂多变量传染病数据的预测精度和解释能力。具体目标包括：
第一，设计并实现一种新型混合架构，融合M-TCN的局部特征提取能力与LSTM的序列建模优势，通过并行-串行组合方式实现多层次时序特征学习。
第二，引入变量间注意力机制与随机注意力正则化，动态捕捉多预测变量在不同时空上下文中的重要性变化，提升模型对关键信号的敏感性和抗干扰能力。
第三，针对传染病数据的特性，优化模型对长期依赖和非周期性冲击的建模能力，通过门控机制和扩张卷积扩大时序感受野，增强对滞后效应和突发事件的适应性。
第四，系统评估模型的预测性能与可解释性，在多源疫情数据集上验证其有效性，并通过注意力可视化、特征消融等方法分析模型决策机制。
2.研究内容
（1）M-TCN-LSTM混合模型构建
研究内容首先聚焦于构建M-TCN-LSTM混合模型的基础架构。M-TCN部分采用多头分离式设计，每个变量单独通过独立的TCN子模型，提取变量特异性特征。TCN子模型由一系列因果卷积层和残差块组成，通过扩张系数递增的扩张卷积确保指数级扩大的感受野。LSTM部分接收M-TCN输出的特征向量，学习跨变量的高阶时间依赖关系。两个组件间采用稠密连接方式，既保留原始时间信息，又融合深层抽象特征。模型末端接入全连接层，将学习到的时间表征映射为预测值（如未来7天、14天的新增病例数）。
（2）注意力机制增强与优化
针对M-TCN简单拼接多变量特征的不足，在Flatten层后引入变量间注意力模块。该模块基于自注意力（Self-Attention）机制，计算公式如下：

其中Q、K、V分别由N个变量的特征向量通过线性变换得到。注意力权重矩阵反映了不同变量对预测任务的相对重要性，使模型能够动态调整特征融合策略。为进一步提升注意力的可靠性和泛化能力，引入随机注意力正则化，通过在训练期间随机丢弃部分注意力权重，迫使模型学习更稳健的特征重要性表示。
（3）面向传染病特点的算法优化
针对传染病的滞后效应和非周期性冲击，设计专门的算法组件。对于滞后效应，在TCN部分采用自适应扩张卷积，根据输入序列长度自动调整扩张系数，确保感受野覆盖可能的滞后周期（如14-21天）。对于非周期性冲击，在LSTM部分引入门控跳跃连接，使模型能够识别突变点并快速调整状态转移。此外，模型还考虑时空异质性，通过图卷积网络（GCN）嵌入区域间人口流动数据，增强对空间传播动态的建模能力。
（4）模型验证与解释框架
构建全面的模型验证框架，在多个公开疫情数据集（如美国COVID-19数据、印度结核病数据等）上评估模型性能。选用RMSE（均方根误差）、MAE（平均绝对误差）和连续排名概率得分（CRPS）作为主要评价指标。针对模型可解释性，开发多级解释框架：在第一级，通过注意力权重量化各输入变量对预测的贡献度；在第二级，采用基于梯度的特征重要性分析方法，计算每个输入特征对输出的偏导数；在第三级，通过反事实推理生成假设场景（如如果人口流动减少50%，预测结果会如何变化），验证模型的因果推理能力。
3.拟解决的关键问题
本研究拟解决的三个关键科学问题如下：
（1）长期依赖与滞后效应的建模问题
传染病传播过程中，防控政策、环境变化等干预措施往往需要一定时间才能显现效果，这种滞后效应使输入与输出间存在复杂的时间延迟关系。传统LSTM模型虽然理论上能学习长期依赖，但实际应用中往往偏向短期模式，而TCN的感受野受扩张系数限制，可能无法充分覆盖长达数周的滞后周期。此外，不同干预措施（如封城、疫苗接种）的滞后周期异质性更加大了建模难度。
解决方案：设计混合感受野机制，在TCN部分采用层次化扩张卷积，底层捕捉短期模式（1-3天），中层捕捉中期模式（7-10天），高层捕捉长期模式（14-21天）。在LSTM部分引入时间注意力机制，强化对关键时间点的关注。通过联合优化，确保模型能够覆盖完整的滞后周期，准确捕捉干预措施与传播动态间的延迟关系。
（2）多变量动态交互与重要性变化问题
传染病预测涉及的多变量（人口流动、天气、政策等）间存在复杂非线性交互，且变量的相对重要性随疫情发展阶段动态变化。现有M-TCN模型采用静态拼接方式融合多变量特征，无法适应这种动态变化。而简单注意力机制在多元时间序列中的直接应用，往往忽略了变量间的相互依赖关系。
解决方案：引入时空动态注意力机制，从时间和变量两个维度自适应调整特征重要性。时间维度注意力捕捉同一变量在不同疫情阶段的重要性变化，变量维度注意力建模不同变量在同一时间点的交互效应。结合随机注意力正则化，避免模型过度依赖少数伪相关特征，提升在分布外样本上的泛化能力。
（3）模型可解释性与可靠性提升问题
深度学习模型在传染病预测中的实际应用，很大程度上受限于其黑盒特性和决策透明度不足。标准注意力机制被证明不能提供可靠的特征重要性解释，而单纯追求预测精度可能使模型学习数据中的伪相关模式，导致在真实场景中失效。
解决方案：构建多层次可解释性框架，结合先验知识约束与数据驱动学习。在注意力机制中引入流行病学先验，如基于基本再生数R0的注意力初始化。采用基于梯度的特征重要性分析方法作为注意力权重的补充验证。开发反事实解释模块，量化不同控制措施对预测结果的潜在影响，为决策者提供直观的政策评估工具。

二、拟采取的研究方法（或技术路线、实验方案）及可行性分析
1.研究方法与技术路线
（1）数据准备与预处理
研究使用多源异构数据，包括：①疫情数据（每日新增确诊病例、死亡病例、康复病例）；②人口流动数据（手机定位、交通枢纽人流指数）；③环境数据（温度、湿度、紫外线强度）；④干预政策数据（封城等级、社交距离要求、疫苗接种率）。所有数据统一时间粒度（日度）和地理尺度（省级/州级），并对缺失值采用时空克里金插值方法填补。
考虑到疫情数据的非平稳性和时空异质性，采用Box-Cox变换稳定方差，使用差分和移动平均比率法消除趋势项。针对数据中存在的异常值（如由于报告延迟导致的零星峰值），结合流行病学先验知识进行平滑处理。
（2）模型架构设计
模型整体架构如下所示：
表1 注意力增强M-TCN-LSTM模型架构
模块	组件	功能	输出
输入层	多变量时间序列窗口	接收原始数据	（批次大小, 时间步长, 变量数）
M-TCN模块	N个并行TCN子网络	提取变量特异性时间模式	（批次大小, 时间步长, N×特征维度）
注意力增强层	变量间自注意力机制+随机丢弃	动态加权多变量特征	（批次大小, 时间步长, N×特征维度）
LSTM模块	双层双向LSTM	学习跨变量时序依赖	（批次大小, 隐藏单元数）
输出层	全连接层+线性激活	生成预测结果	（批次大小, 预测步长）
M-TCN模块中，每个TCN子网络包含4个残差块，每个残差块的扩张系数按2的指数增长（1,2,4,8），确保感受野覆盖足够长的时间窗口。注意力增强层采用缩放点积注意力机制，并在训练阶段以0.1的概率随机置零部分注意力权重，提升泛化能力。LSTM模块隐藏单元数根据输入维度动态调整，一般设置为输入特征维度的1.5-2倍。
（3）模型训练与优化
模型训练采用多阶段策略，首先分别预训练M-TCN和LSTM组件，然后进行端到端联合微调。损失函数结合RMSE损失和时序一致性正则项，避免预测轨迹出现非生理性震荡。优化器使用AdamW，初始学习率设为0.001，并采用余弦退火调度器动态调整。
针对传染病数据中的类别不平衡问题（如爆发期与非爆发期样本数量不均），采用时间感知加权采样策略，提高关键转折点在训练中的权重。模型验证采用时序交叉验证，严格防止未来信息泄露，确保评估结果的可靠性。
（4）评估与解释方法
模型性能评估采用多种指标：RMSE和MAE衡量点预测精度，CRPS评估概率预测性能，MAPE（平均绝对百分比误差）评估相对误差。统计显著性检验采用Diebold-Mariano测试，比较模型预测性能的差异是否显著。
可解释性分析采用多方法三角验证策略：首先可视化注意力权重，观察模型关注的重点变量和时间点；然后计算基于梯度的特征重要性得分，验证注意力权重的可靠性；最后进行消融实验，通过系统性移除某些输入特征，量化其对预测性能的影响。此外，还使用反事实分析方法，生成不同干预情景下的预测结果，辅助决策者理解模型的决策机制。
2.可行性分析
（1）理论可行性
本研究构建的混合模型基于成熟深度学习理论，各部分组件均有理论支持：TCN的因果卷积和扩张卷积为序列建模提供了有效方法；LSTM的门控机制被证明能够有效捕捉时间依赖；注意力机制在多个领域展示了强大的特征选择能力。近年来，混合模型在传染病预测中的成功应用为本研究提供了有力佐证，如LSTM-GNN模型在医院感染预测中达到78.96%的准确率，TCN与自注意力结合的混合模型在交通预测中显著降低误差。这些前期研究成果从理论上支持了本项目技术路线的可行性。
（2）数据可行性
本研究所需数据来自多个公开渠道，包括：美国COVID-19数据（约翰斯·霍普金斯大学数据库）、欧洲流感数据（欧洲疾控中心）、印度结核病数据（世界卫生组织全球结核病报告）等。这些数据集规模充足、质量可靠，且包含多变量信息。此外，项目还可以使用多个权威合成数据集，如基于真实医院动态生成的合成医院感染数据集，这些数据专门为评估预测模型设计，包含了已知的传播动态和干预效果，为模型验证提供了理想基准。
（3）技术可行性
研究团队已掌握深度学习模型开发的核心技术，具备丰富的PyTorch和TensorFlow框架使用经验。计算资源方面，项目可使用配备NVIDIA V100 GPU的高性能计算集群，满足大规模时序数据训练的需求。软件生态方面，现有深度学习库（如PyTorch Geometric、Transformers）提供了模型关键组件的高效实现，显著降低了开发难度。























